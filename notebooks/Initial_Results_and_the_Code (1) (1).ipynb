{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "ZT9Hp0ScNhrW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lT1o2eNUEy74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "1fb56108-ea96-431b-98a4-936bfe8f3fe1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'risk_factors_cervical_cancer.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2412443056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"risk_factors_cervical_cancer.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'risk_factors_cervical_cancer.csv'"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"risk_factors_cervical_cancer.csv\")\n",
        "\n",
        "print(df.shape)\n",
        "print(df.dtypes)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize missing values\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Replace '?' with NaN\n",
        "df = df.replace(\"?\", np.nan)\n",
        "\n",
        "# Convert to numeric where possible\n",
        "for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "# Missingness summary\n",
        "missing_pct = (df.isna().mean() * 100).sort_values(ascending=False)\n",
        "missing_table = pd.DataFrame({\n",
        "    \"feature\": missing_pct.index,\n",
        "    \"missing_percent\": missing_pct.values.round(1)\n",
        "})\n",
        "\n",
        "missing_table.head(15)\n"
      ],
      "metadata": {
        "id": "6_Ys0KxKBXbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target distribution\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "target = \"Biopsy\"\n",
        "\n",
        "counts = df[target].value_counts()\n",
        "perc = (counts / len(df) * 100).round(2)\n",
        "\n",
        "biopsy_table = pd.DataFrame({\n",
        "    \"Count\": counts,\n",
        "    \"Percentage (%)\": perc\n",
        "})\n",
        "\n",
        "print(biopsy_table)\n",
        "\n",
        "counts.plot(kind=\"bar\")\n",
        "plt.title(\"Biopsy outcome counts\")\n",
        "plt.xlabel(\"Biopsy\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sC5mJVpI84v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics for key numeric variables\n",
        "\n",
        "key_numeric = [\n",
        "    \"Age\",\n",
        "    \"Number of sexual partners\",\n",
        "    \"First sexual intercourse\",\n",
        "    \"Num of pregnancies\",\n",
        "    \"Smokes (years)\",\n",
        "    \"Smokes (packs/year)\",\n",
        "    \"Hormonal Contraceptives (years)\",\n",
        "    \"IUD (years)\",\n",
        "    \"STDs (number)\",\n",
        "    \"STDs: Number of diagnosis\"\n",
        "]\n",
        "\n",
        "key_numeric = [c for c in key_numeric if c in df.columns]\n",
        "\n",
        "desc = df[key_numeric].describe().T\n",
        "desc[\"missing\"] = df[key_numeric].isna().sum()\n",
        "desc[\"missing_pct\"] = (desc[\"missing\"] / len(df) * 100).round(1)\n",
        "\n",
        "desc = desc[[\"count\",\"missing\",\"missing_pct\",\"mean\",\"std\",\"min\",\"25%\",\"50%\",\"75%\",\"max\"]].round(2)\n",
        "desc\n"
      ],
      "metadata": {
        "id": "uNa2V_K4FkeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Age Distribution Histogram\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.hist(df[\"Age\"].dropna(), bins=20)\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Age\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nVRCxRdoGsbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outlier Detection Boxplot\n",
        "\n",
        "vars_box = [\n",
        "    \"Number of sexual partners\",\n",
        "    \"Num of pregnancies\",\n",
        "    \"Smokes (packs/year)\",\n",
        "    \"Hormonal Contraceptives (years)\"\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(9,4))\n",
        "plt.boxplot([df[v].dropna() for v in vars_box], tick_labels=vars_box, vert=False)\n",
        "plt.title(\"Boxplots for selected numeric variables\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1-ACd27-G3RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "VxkevoG-N8OI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop features:\n",
        "\n",
        "# Columns that represent diagnostic results or post-screening outcomes\n",
        "leakage_cols = [\n",
        "    \"Hinselmann\",\n",
        "    \"Schiller\",\n",
        "    \"Citology\",\n",
        "    \"Dx\",\n",
        "    \"Dx:Cancer\",\n",
        "    \"Dx:CIN\",\n",
        "    \"Dx:HPV\"\n",
        "]\n",
        "\n",
        "# Drop leakage features\n",
        "df_prep = df.drop(columns=leakage_cols)\n",
        "print(\"Dropped leakage features:\")\n",
        "print(leakage_cols)\n",
        "print(\"\")\n",
        "\n",
        "# Drop features with more than 90% missing data\n",
        "missing_threshold = 0.90\n",
        "high_missing_cols = df_prep.columns[df_prep.isna().mean() > missing_threshold]\n",
        "\n",
        "print(\"Dropped due to high missingness:\")\n",
        "print(high_missing_cols.tolist())\n",
        "print(\"\")\n",
        "\n",
        "df_prep = df_prep.drop(columns=high_missing_cols)\n",
        "print(\"Remaining Shape:\", df_prep.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "IBi_XD9tH6Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables representing diagnostic outcomes or screening test results (including Hinselmann, Schiller, Citology, and cancer diagnosis indicators) were excluded prior to modeling. These variables are strongly correlated with the biopsy outcome but reflect downstream clinical decisions rather than true risk factors. Including them would introduce information leakage and artificially inflate model performance. Removing these features ensures that the model learns from upstream risk characteristics rather than proxy diagnostic signals.\n",
        "\n",
        "Features with more than 90% missing values were removed from the dataset. Variables related to the timing of STD diagnoses fell into this category, indicating that they were rarely recorded. Retaining such features would significantly reduce usable sample size or require speculative imputation. Excluding these variables improves data reliability and model stability."
      ],
      "metadata": {
        "id": "cK0MmMCmaqhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for imputation and scaling by identifying feature types\n",
        "\n",
        "# Separate features and target\n",
        "X = df_prep.drop(columns=[target])\n",
        "y = df_prep[target]\n",
        "\n",
        "# Identify numeric and binary features\n",
        "binary_features = [c for c in X.columns if X[c].dropna().isin([0,1]).all()]\n",
        "numeric_features = [c for c in X.columns if c not in binary_features]\n",
        "\n",
        "print(\"Binary features:\", binary_features)\n",
        "print(\"Numeric features:\", numeric_features)\n"
      ],
      "metadata": {
        "id": "09h0T2U9KFQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictor variables were grouped into binary and continuous numeric features. Binary indicators represent the presence or absence of behaviors or conditions, while numeric features capture intensity or duration of exposure. This separation allows for appropriate preprocessing strategies, including median imputation and scaling for numeric variables while preserving the interpretability of binary indicators."
      ],
      "metadata": {
        "id": "ByhjYSfEanES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Impute numeric features with median\n",
        "num_imputer = SimpleImputer(strategy=\"median\")\n",
        "X[numeric_features] = num_imputer.fit_transform(X[numeric_features])\n",
        "\n",
        "# Impute binary features with most frequent value\n",
        "bin_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "X[binary_features] = bin_imputer.fit_transform(X[binary_features])\n",
        "\n",
        "\n",
        "# Check remaining missing values\n",
        "print(\"Remaining missing values:\", X.isna().sum().sum())\n"
      ],
      "metadata": {
        "id": "QnS2GzcpKR8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To preserve sample size and reduce bias, missing values were imputed rather than removing observations. Median imputation was applied to numeric variables to reduce sensitivity to skewed distributions and outliers. Binary variables were imputed using the most frequent value, maintaining their categorical interpretation. After imputation, no missing values remained in the feature set."
      ],
      "metadata": {
        "id": "O94MIz_Zafui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X[numeric_features] = scaler.fit_transform(X[numeric_features])\n"
      ],
      "metadata": {
        "id": "vHlwlxn-KdoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuous numeric variables were standardized using z-score normalization to ensure that features with larger numeric ranges did not disproportionately influence model training. Binary variables were not scaled to preserve their interpretability. Scaling was performed after imputation to ensure valid transformations."
      ],
      "metadata": {
        "id": "6tC4KFQuabXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split with stratification\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "v_BrsVtJKgCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train–test split.**\n",
        "\n",
        "The dataset was split into training (75%) and testing (25%) subsets using stratified sampling to preserve the class distribution of the Biopsy outcome. Stratification is particularly important given the strong class imbalance and ensures that both sets contain representative positive and negative cases."
      ],
      "metadata": {
        "id": "Q-5ku6wIaRhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report,\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        ")\n",
        "\n",
        "def evaluate_model(name, model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Some models support predict_proba\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "        auc = roc_auc_score(y_test, y_proba)\n",
        "    else:\n",
        "        y_proba = None\n",
        "        auc = None\n",
        "\n",
        "    print(f\"\\n==== {name} ====\")\n",
        "    print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
        "    print(\"Precision:\", round(precision_score(y_test, y_pred, zero_division=0), 4))\n",
        "    print(\"Recall:\", round(recall_score(y_test, y_pred, zero_division=0), 4))\n",
        "    print(\"F1:\", round(f1_score(y_test, y_pred, zero_division=0), 4))\n",
        "    if auc is not None:\n",
        "        print(\"ROC-AUC:\", round(auc, 4))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "id": "SvVVnlujdDBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=2000, random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "evaluate_model(\"Logistic Regression (Unweighted)\", lr, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "FRG9hznOdMlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression (Unweighted)**\n",
        "\n",
        "The unweighted logistic regression model achieved an accuracy of 93.5%, but failed to identify any positive biopsy cases. Precision, recall, and F1-score for the positive class were all 0.00, indicating that the model predicted all observations as belonging to the negative class. Despite this, the model achieved a ROC-AUC of 0.62, suggesting some underlying discriminatory signal that is not reflected at the default classification threshold.\n",
        "\n",
        "These results demonstrate that accuracy alone is misleading in the presence of class imbalance. Although the model separates risk reasonably well in probability space, it does not cross the decision threshold required to predict positive cases. This highlights the importance of explicitly addressing imbalance rather than relying on default model settings."
      ],
      "metadata": {
        "id": "qimSZXrOdxMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_bal = LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=42)\n",
        "lr_bal.fit(X_train, y_train)\n",
        "\n",
        "evaluate_model(\"Logistic Regression (Class-Weighted)\", lr_bal, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "k2bG3ykVdPo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression (Class-Weighted)**\n",
        "\n",
        "Applying class weights substantially altered model behavior. Accuracy decreased to 75.4%, while recall for the positive class increased to 0.50, indicating that half of biopsy-positive cases were correctly identified. Precision remained low (0.13), resulting in an F1-score of 0.21. The ROC-AUC (0.62) remained similar to the unweighted model.\n",
        "\n",
        "Class weighting successfully shifted the model toward identifying positive cases, confirming that imbalance was suppressing recall in the unweighted model. The tradeoff between recall and precision is expected in medical screening contexts, where sensitivity is often prioritized. These results suggest that logistic regression can capture meaningful risk patterns, but threshold selection and cost-sensitive tuning are necessary for practical use."
      ],
      "metadata": {
        "id": "ESMSNH5Yd6UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "recall_scores = cross_val_score(\n",
        "    lr_bal, X, y, cv=cv, scoring=\"recall\"\n",
        ")\n",
        "\n",
        "recall_scores, recall_scores.mean()\n"
      ],
      "metadata": {
        "id": "RYj0yYD6ejHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stratified Cross-Validation (Model Stability)**\n",
        "\n",
        "To obtain a more reliable estimate of model performance and reduce sensitivity to a single train–test split, stratified 5-fold cross-validation was performed using the class-weighted logistic regression model. Stratification preserves the proportion of positive biopsy outcomes in each fold, which is essential given the severe class imbalance.\n",
        "\n",
        "**Results (Recall across folds).**\n",
        "\n",
        "0.36, 0.18, 0.18, 0.45, 0.36\n",
        "\n",
        "The mean cross-validated recall was **0.31.**\n",
        "\n",
        "These results indicate that recall varies across folds, which is expected in a small dataset with relatively few positive cases. However, the model consistently identifies a meaningful portion of positive biopsy cases across multiple splits, supporting the conclusion that class-weighted logistic regression improves sensitivity relative to unweighted approaches. The variability also highlights the importance of reporting fold-based performance estimates and supports future refinement through threshold tuning or resampling methods to further stabilize minority-class detection."
      ],
      "metadata": {
        "id": "QdcK7pmie_6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "evaluate_model(\"Decision Tree (max_depth=5)\", tree, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "xJvuiwvMdTR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree (max depth = 5)**\n",
        "\n",
        "The decision tree achieved an accuracy of 91.2% but, like the unweighted logistic regression, failed to identify any positive biopsy cases. Recall and precision for the positive class were 0.00, and ROC-AUC dropped to 0.45, indicating performance close to random guessing.\n",
        "\n",
        "Despite its ability to model non-linear relationships, the decision tree defaulted to majority-class predictions. This suggests that shallow trees may be insufficient to capture subtle risk patterns in a highly imbalanced clinical dataset, especially when positive cases are rare."
      ],
      "metadata": {
        "id": "0VYYeBvwd-f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced_subsample\"\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "evaluate_model(\"Random Forest (Balanced)\", rf, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "KGyW4bSWdWJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest (Class-Balanced)**\n",
        "\n",
        "The class-balanced random forest achieved 93.5% accuracy and the highest ROC-AUC among tested models (0.70). However, recall for the positive class remained low (0.07), with only one positive case correctly identified. Precision for positive predictions was 0.50, reflecting very few but more confident positive predictions.\n",
        "\n",
        "The random forest demonstrated stronger overall discrimination than other models, as reflected by ROC-AUC, but still struggled to identify positive cases at the default threshold. This suggests that while the model captures meaningful signal, threshold adjustment or alternative imbalance-handling strategies are required to translate probability separation into clinically useful predictions."
      ],
      "metadata": {
        "id": "ZEtDQhpKeEtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Compute imbalance ratio\n",
        "neg, pos = y_train.value_counts()\n",
        "scale_pos_weight = neg / pos\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "evaluate_model(\"XGBoost (Class-Weighted)\", xgb, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "T1zOeMKvcw-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost Classifier (Class-Weighted)**\n",
        "\n",
        "The class-weighted XGBoost model achieved an overall accuracy of 85.6% and a ROC-AUC of 0.54. Precision for the positive Biopsy class was 0.10, recall was 0.14, and the resulting F1-score was 0.11. The confusion matrix shows that the model correctly identified 2 out of 14 positive biopsy cases, while misclassifying a larger number of negative cases as positive compared to previous models.\n",
        "\n",
        "Although XGBoost is capable of modeling complex non-linear relationships, its performance in this setting did not substantially improve minority-class detection compared to class-weighted logistic regression. The relatively low ROC-AUC suggests limited additional discriminatory power beyond simpler models. This outcome may reflect the small number of positive cases, high feature sparsity, and remaining noise in clinical history variables. These results indicate that model complexity alone is insufficient to overcome severe class imbalance and data limitations without further tuning or alternative imbalance-handling strategies."
      ],
      "metadata": {
        "id": "492XwgXZdpCi"
      }
    }
  ]
}